[id="adopting-compute-services-to-the-data-plane_{context}"]

= Adopting Compute services to the {rhos_acro} data plane with a failed Compute Node

Adopt your Compute (nova) services to the {rhos_long} data plane.

//kgilliga: The following text belongs under the code block in step 6 but I'm unable to hide it there: "For multi-cell, config maps and {rhos_prev_long} data plane services should be named like `nova-custom-ceph-cellX` and `nova-compute-extraconfig-cellX`."

.Prerequisites

* You have stopped the remaining control plane nodes, repositories, and packages on the {compute_service_first_ref} hosts. For more information, see xref:stopping-infrastructure-management-and-compute-services_{context}[Stopping infrastructure management and Compute services].
* In the bastion, create the dataplane network (IPAM):
+
[source,bash,role=execute,subs=attributes]
----
cd /home/lab-user/labrepo/content/files/
oc apply -f osp-ng-dataplane-netconfig-adoption.yaml
----
+

* Get the libvirt secret password:
+
[source,bash,role=execute]
----
LIBVIRT_PASSWORD=$(cat ~/tripleo-standalone-passwords.yaml | grep ' LibvirtTLSPassword:' | awk -F ': ' '{ print $2; }')
LIBVIRT_PASSWORD_BASE64=$(echo -n "$LIBVIRT_PASSWORD" | base64)
----
+

* Create the libvirt secret:
+
[source,yaml]
----
oc apply -f - <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: libvirt-secret
  namespace: openstack
type: Opaque
data:
  LibvirtPassword: ${LIBVIRT_PASSWORD_BASE64}
EOF
----
+

* You have defined the shell variables to run the script that runs the fast-forward upgrade:
+
[source,bash,role=execute,subs=attributes]
----
PODIFIED_DB_ROOT_PASSWORD=$(oc get -o json secret/osp-secret | jq -r .data.DbRootPassword | base64 -d)

alias openstack="oc exec -t openstackclient -- openstack"
declare -A computes
computes=(
  ["compute02.localdomain"]="172.22.0.110"
  ["compute03.localdomain"]="172.22.0.112"
)
----

.Procedure

ifeval::["{build}" != "downstream"]
. Create a https://kubernetes.io/docs/concepts/configuration/secret/#ssh-authentication-secrets[ssh authentication secret] for the data plane nodes:
//kgilliga:I need to check if we will document this in Red Hat docs.
endif::[]
ifeval::["{build}" != "upstream"]
. Create an SSH authentication secret for the data plane nodes:
endif::[]
+
[source,bash,role=execute,subs=attributes]
----
oc create secret generic dataplane-ansible-ssh-private-key-secret \
--save-config \
--dry-run=client \
--from-file=authorized_keys=/home/lab-user/.ssh/{guid}key.pub \
--from-file=ssh-privatekey=/home/lab-user/.ssh/{guid}key.pem \
--from-file=ssh-publickey=/home/lab-user/.ssh/{guid}key.pub \
-n openstack \
-o yaml | oc apply -f-
----
+
ifeval::["{build}" == "downstream"]
* Replace `/home/lab-user/.ssh/{guid}key.pem` with the path to your SSH key.
endif::[]

. Generate an ssh key-pair `nova-migration-ssh-key` secret:
+
[source,bash,role=execute,subs=attributes]
----
cd "$(mktemp -d)"
ssh-keygen -f ./id -t ecdsa-sha2-nistp521 -N ''
oc get secret nova-migration-ssh-key || oc create secret generic nova-migration-ssh-key \
  -n openstack \
  --from-file=ssh-privatekey=id \
  --from-file=ssh-publickey=id.pub \
  --type kubernetes.io/ssh-auth
rm -f id*
cd -
----

. As we use a local storage back end for libvirt, create a `nova-compute-extra-config` service to remove pre-fast-forward workarounds and configure Compute services to use a local storage back end:
+
[source,bash,role=execute,subs=attributes]
----
cat << EOF | oc apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: nova-extra-config
  namespace: openstack
data:
  19-nova-compute-cell1-workarounds.conf: |
    [workarounds]
    disable_compute_service_check_for_ffu=true
EOF
----
+
[NOTE]
The secret `nova-cell<X>-compute-config` auto-generates for each
`cell<X>`. You must specify values for the `nova-cell<X>-compute-config` and `nova-migration-ssh-key` parameters for each custom `OpenStackDataPlaneService` CR that is related to the {compute_service}.

+
The resources in the `ConfigMap` contain cell-specific configurations.

. Create a secret for the subscription manager:
+
[source,yaml,role=execute]
----
oc create secret generic subscription-manager \
--from-literal rhc_auth='{"login": {"username": "<subscription_manager_username>", "password": "<subscription_manager_password>"}}'
oc create secret generic subscription-manager-2 \
--from-literal rhc_auth='{"login": {"username": "<subscription_manager_username>", "password": "<subscription_manager_password>"}}'
----
+
* Replace `<subscription_manager_username>` with the applicable user name in base64 encoding.
* Replace `<subscription_manager_password>` with the applicable password in base64 encoding.

. Create a secret for the Red Hat registry:
+
----
$ oc create secret generic redhat-registry \
--from-literal edpm_container_registry_logins='{"registry.redhat.io": {"<registry_username>": "<registry_password>"}}'
----
+
* Replace `<registry_username>` with the applicable user name in base64 encoding.
* Replace `<registry_password>` with the applicable password in base64 encoding

. Create the `OpenStackDataPlaneNodeSet` CRs corresponding to compute02 and compute03:
+
[source,bash,role=execute,subs=attributes]
----
oc apply -f osp-ng-dataplane-node-set-deploy-adoption-compute-2.yaml
oc apply -f osp-ng-dataplane-node-set-deploy-adoption-compute-3.yaml
----

* Take some time to go through the *osp-ng-dataplane-adoption-compute-2.yaml* file and *osp-ng-dataplane-adoption-compute-3.yaml* files. We have configured the edpm_ovn_bridge_mappings with "datacentre:br-ex"

. Run the pre-adoption validation:

.. Create the validation service:
+
[source,bash,role=execute,subs=attributes]
----
cat << EOF | oc apply -f -
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneService
metadata:
  name: pre-adoption-validation
spec:
  playbook: osp.edpm.pre_adoption_validation
EOF
----

.. Create a `OpenStackDataPlaneDeployment` CR that runs only the validation:
+
[source,bash,role=execute,subs=attributes]
----
cat << EOF | oc apply -f -
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneDeployment
metadata:
  name: openstack-pre-adoption
spec:
  nodeSets:
  - compute-2
  - compute-3
  servicesOverride:
  - pre-adoption-validation
EOF
----

.. When the validation is finished, confirm that the status of the Ansible EE pods is `Completed`:
+
[source,bash,role=execute,subs=attributes]
----
watch oc get pod -l app=openstackansibleee
----
+
[source,bash,role=execute,subs=attributes]
----
oc logs -l app=openstackansibleee -f --max-log-requests 20
----

.. Wait for the deployment to reach the `Ready` status:
+
[source,bash,role=execute,subs=attributes]
----
oc wait --for condition=Ready openstackdataplanedeployment/openstack-pre-adoption --timeout=10m
----
+
[IMPORTANT]
====
If any openstack-pre-adoption validations fail, you must reference the Ansible logs to determine which ones were unsuccessful, and then try the following troubleshooting options:

* If the hostname validation failed, check that the hostname of the data plane
node is correctly listed in the `OpenStackDataPlaneNodeSet` CR.

* If the kernel argument check failed, ensure that the kernel argument configuration in the `edpm_kernel_args` and `edpm_kernel_hugepages` variables in the `OpenStackDataPlaneNodeSet` CR is the same as the kernel argument configuration that you used in the {rhos_prev_long} ({OpenStackShort}) {rhos_prev_ver} node.

* If the tuned profile check failed, ensure that the
`edpm_tuned_profile` variable in the `OpenStackDataPlaneNodeSet` CR is configured
to use the same profile as the one set on the {OpenStackShort} {rhos_prev_ver} node.
====

. Remove the remaining {OpenStackPreviousInstaller} services:

.. Create an `OpenStackDataPlaneService` CR to clean up the data plane services you are adopting:
+
[source,bash,role=execute,subs=attributes]
----
cat << EOF | oc apply -f -
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneService
metadata:
  name: tripleo-cleanup
spec:
  playbook: osp.edpm.tripleo_cleanup
EOF
----

.. Create the `OpenStackDataPlaneDeployment` CR to run the clean-up:
+
[source,bash,role=execute,subs=attributes]
----
cat << EOF | oc apply -f -
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneDeployment
metadata:
  name: tripleo-cleanup
spec:
  nodeSets:
  - compute-2
  - compute-3
  servicesOverride:
  - tripleo-cleanup
EOF
----

. When the clean-up is finished, deploy the `OpenStackDataPlaneDeployment` CR:
+
[source,bash,role=execute,subs=attributes]
----
cat << EOF | oc apply -f -
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneDeployment
metadata:
  name: openstack-edpm-compute
spec:
  nodeSets:
  - compute-2
  - compute-3
EOF
----

. You should see that *compute02* jobs are progressing, however *compute03* fails in the bootstrap service
+
[source,bash,role=execute,subs=attributes]
----
oc get jobs -n openstack
----

----
NAME                                                              COMPLETIONS   DURATION   AGE
bootstrap-openstack-edpm-compute-compute-2     1/1           78s        5m37s
bootstrap-openstack-edpm-compute-compute-3     0/1           5m37s      5m37s
configure-network-openstack-edpm-compute-openstack-edpm-compute   1/1           48s        98s
configure-os-openstack-edpm-compute-compute    0/1           9s         9s
download-cache-openstack-edpm-compute-openstack-edpm-compute-se   1/1           2m41s      4m19s
install-os-openstack-edpm-compute-compute-2    1/1           35s        44s
keystone-cron-29012581                                            1/1           5s         143m
keystone-cron-29012641                                            1/1           5s         83m
keystone-cron-29012701                                            1/1           5s         23m
pre-adoption-validation-openstack-pre-adoption-openstack-edpm-c   1/1           23s        6h27m
tripleo-cleanup-tripleo-cleanup-compute        1/1           4m57s      6h26m
validate-network-openstack-edpm-compute-openstack-edpm-compute    1/1           6s         50s
----
. If we check the *compute03* logs, there are errors to download the RPM packages
+
[source,bash,role=execute,subs=attributes]
----
oc logs job/bootstrap-openstack-edpm-compute-compute-3 -n openstack
----
----
TASK [osp.edpm.edpm_bootstrap : Install required packages to bootstrap EDPM] ***
task path: /usr/share/ansible/collections/ansible_collections/osp/edpm/roles/edpm_bootstrap/tasks/packages.yml:43
FAILED - RETRYING: [compute03]: Install required packages to bootstrap EDPM (5 retries left).
FAILED - RETRYING: [compute03]: Install required packages to bootstrap EDPM (4 retries left).
FAILED - RETRYING: [compute03]: Install required packages to bootstrap EDPM (3 retries left).
FAILED - RETRYING: [compute03]: Install required packages to bootstrap EDPM (2 retries left).
FAILED - RETRYING: [compute03]: Install required packages to bootstrap EDPM (1 retries left).
fatal: [compute03]: FAILED! => {"ansible_facts": {"pkg_mgr": "dnf"}, "attempts": 5, "changed": false, "failed_when_result": true, "msg": "Failed to download metadata for repo 'rhel-9-for-x86_64-baseos-rpms': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried", "rc": 1, "results": []}

NO MORE HOSTS LEFT *************************************************************

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
compute03                  : ok=14   changed=3    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0
----
. Connect to the *compute03*:
+
[source,bash,role=execute,subs=attributes]
----
ssh -i /home/lab-user/.ssh/{guid}key.pem cloud-user@compute03
----
. Revert back the DNS configuration:
+
[source,bash,role=execute,subs=attributes]
----
sudo cp /root/resolv.conf.bck /etc/resolv.conf
----
. Delete the facts.d folder as it's used to mark the execution of bootstrap_command as completed. By deleting the bootstrap command can be reexecuted:
+
[source,bash,role=execute,subs=attributes]
----
sudo rm -rf /etc/ansible/facts.d
----
. Create a new OpenStackDataPlaneDeployment adding only the *compute-3* nodeset corresponding to the *compute03*
+
[source,bash,role=execute,subs=attributes]
----
cat << EOF | oc apply -f -
apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneDeployment
metadata:
  name: openstack-edpm-compute-recover-3
spec:
  nodeSets:
  - compute-3
EOF
----
. You should see that now *compute03* jobs are progressing
+
[source,bash,role=execute,subs=attributes]
----
oc get jobs -n openstack
----
+

.Verification

. Confirm that all the Ansible EE pods reach a `Completed` status:
+
[source,bash,role=execute,subs=attributes]
----
watch oc get pod -l app=openstackansibleee
----
+
[source,bash,role=execute,subs=attributes]
----
oc logs -l app=openstackansibleee -f --max-log-requests 30
----

. Wait for the data plane node set to reach the `Ready` status:
+
[source,bash,role=execute,subs=attributes]
----
oc wait --for condition=Ready osdpns/openstack-edpm-compute-recover-3 --timeout=30m
----

. Verify that the {networking_first_ref} agents are running:
+
[source,bash,role=execute,subs=attributes]
----
oc exec openstackclient -- openstack network agent list
+--------------------------------------+------------------------------+------------------------+-------------------+-------+-------+----------------------------+
| ID                                   | Agent Type                   | Host                   | Availability Zone | Alive | State | Binary                     |
+--------------------------------------+------------------------------+------------------------+-------------------+-------+-------+----------------------------+
| 174fc099-5cc9-4348-b8fc-59ed44fcfb0e | DHCP agent                   | standalone.localdomain | nova              | :-)   | UP    | neutron-dhcp-agent         |
| 10482583-2130-5b0d-958f-3430da21b929 | OVN Metadata agent           | standalone.localdomain |                   | :-)   | UP    | neutron-ovn-metadata-agent |
| a4f1b584-16f1-4937-b2b0-28102a3f6eaa | OVN Controller agent         | standalone.localdomain |                   | :-)   | UP    | ovn-controller             |
+--------------------------------------+------------------------------+------------------------+-------------------+-------+-------+----------------------------+

----

.Next steps

* You must perform a fast-forward upgrade on your Compute services. For more information, see xref:performing-a-fast-forward-upgrade-on-compute-services_{context}[Performing a fast-forward upgrade on Compute services].
